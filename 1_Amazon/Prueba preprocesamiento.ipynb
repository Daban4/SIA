{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ae99ca-7a22-4e85-b156-1071f89ee5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alumno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alumno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Descargar stopwords de NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "spacy.cli.download(\"en_core_web_sm\")  # Descargar el modelo de spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Cargar modelo de spaCy en inglés\n",
    "\n",
    "# Cargar stopwords en inglés de NLTK\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Ejemplo de review con su puntuación\n",
    "reviews = [\n",
    "    (\"The product is amazing! I love it so much. Highly recommended!\", 5),\n",
    "    (\"It's okay, not the best but not the worst either.\", 3),\n",
    "    (\"Terrible experience. The quality is very bad.\", 1)\n",
    "]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 1. Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Eliminar caracteres especiales y números\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # 3. Tokenización y lematización con spaCy\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.lemma_ not in stop_words and not token.is_punct]\n",
    "    \n",
    "    # 4. Unir tokens procesados\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Aplicar preprocesamiento a cada review\n",
    "processed_reviews = [(preprocess_text(text), score) for text, score in reviews]\n",
    "\n",
    "# Convertir a DataFrame para su uso en ML\n",
    "df = pd.DataFrame(processed_reviews, columns=['review', 'score'])\n",
    "\n",
    "# Vectorización con TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['review'])\n",
    "y = df['score']\n",
    "\n",
    "# Verificar si hay suficientes datos para dividir\n",
    "if len(df) > 1:\n",
    "    # División de datos para entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Entrenar un modelo simple (Naive Bayes)\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluación\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')\n",
    "else:\n",
    "    print(\"No hay suficientes datos para entrenar el modelo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b21f5-7258-4122-afe0-0b4c9a6d11fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py311ml]",
   "language": "python",
   "name": "conda-env-.conda-py311ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
